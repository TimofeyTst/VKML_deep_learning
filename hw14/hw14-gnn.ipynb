{"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":30627,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# Install required packages.\n# %%capture\n\n# !pip install torch-geometric\n# !pip install sentence_transformers","metadata":{"id":"GJaiF8Lby2Dm","execution":{"iopub.status.busy":"2023-12-16T13:15:54.204618Z","iopub.execute_input":"2023-12-16T13:15:54.205035Z","iopub.status.idle":"2023-12-16T13:15:54.209795Z","shell.execute_reply.started":"2023-12-16T13:15:54.204984Z","shell.execute_reply":"2023-12-16T13:15:54.208697Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"import torch\nimport torch.nn.functional as F\nfrom torch.nn import Linear\nfrom torch_geometric.datasets import MovieLens\nfrom torch_geometric.nn import GCNConv, SAGEConv, to_hetero\nimport torch_geometric.transforms as T\nimport numpy as np","metadata":{"id":"MYtBy-ZGy7lb","execution":{"iopub.status.busy":"2023-12-16T13:24:12.499523Z","iopub.execute_input":"2023-12-16T13:24:12.500257Z","iopub.status.idle":"2023-12-16T13:24:12.505130Z","shell.execute_reply.started":"2023-12-16T13:24:12.500225Z","shell.execute_reply":"2023-12-16T13:24:12.504218Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"dataset_path = '/tmp/'\ndataset = MovieLens(root=dataset_path)","metadata":{"id":"IsDp2bXpy7n-","execution":{"iopub.status.busy":"2023-12-16T13:16:29.886277Z","iopub.execute_input":"2023-12-16T13:16:29.886808Z","iopub.status.idle":"2023-12-16T13:16:51.413963Z","shell.execute_reply.started":"2023-12-16T13:16:29.886775Z","shell.execute_reply":"2023-12-16T13:16:51.412891Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stderr","text":"Downloading https://files.grouplens.org/datasets/movielens/ml-latest-small.zip\nExtracting /tmp/raw/ml-latest-small.zip\nProcessing...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":".gitattributes:   0%|          | 0.00/1.18k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0bb3d6b6e3314a86881d40ef42b5c8f1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"1_Pooling/config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"96d7a9ccbd8f4d7da71c591b8c431f74"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"README.md:   0%|          | 0.00/10.6k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3476b0232293415e9588770ee81f76ad"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/612 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"80a7c8c6dd7240fa97fd8def22f79949"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d6c1f7fdb03746cbb6de853baf6fb185"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"data_config.json:   0%|          | 0.00/39.3k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"80e9f9e36b0a464da3ad1f9665146311"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"pytorch_model.bin:   0%|          | 0.00/90.9M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ddf65e8be5644d6a99d32194f496321a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a10a458b886d44398184f39ff5e74736"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"27bb0782407b43aea6a1132620200944"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cb1d8632a88b43ecae5696e6b333eb02"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/350 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"36942916d8f5402ea849d770081f36d8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"train_script.py:   0%|          | 0.00/13.2k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8c0e9b7a9bbf43a5ace627c215e0c4d4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"63f370459d2a431f89d48d234ff15f16"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a8d2f717af3b492fa10f05d6d4b9c37d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/305 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8ad9f40394a54035938f98b66198f85c"}},"metadata":{}},{"name":"stderr","text":"Done!\n","output_type":"stream"}]},{"cell_type":"code","source":"device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n\ndata = dataset[0].to(device)\n\n# Add user node features for message passing:\ndata['user'].x = torch.eye(data['user'].num_nodes, device=device)\ndel data['user'].num_nodes\n\n# Add a reverse ('movie', 'rev_rates', 'user') relation for message passing:\ndata = T.ToUndirected()(data)\ndel data['movie', 'rev_rates', 'user'].edge_label  # Remove \"reverse\" label.\n\n# Perform a link-level split into training, validation, and test edges:\ntrain_data, val_data, test_data = T.RandomLinkSplit(\n    num_val=0.1,\n    num_test=0.1,\n    neg_sampling_ratio=0.0,\n    edge_types=[('user', 'rates', 'movie')],\n    rev_edge_types=[('movie', 'rev_rates', 'user')],\n)(data)\n\n\nweight = torch.bincount(train_data['user', 'movie'].edge_label)\nweight = weight.max() / weight","metadata":{"execution":{"iopub.status.busy":"2023-12-16T13:18:10.109597Z","iopub.execute_input":"2023-12-16T13:18:10.109995Z","iopub.status.idle":"2023-12-16T13:18:10.128407Z","shell.execute_reply.started":"2023-12-16T13:18:10.109963Z","shell.execute_reply":"2023-12-16T13:18:10.127346Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"def weighted_mse_loss(pred, target, weight=None):\n    weight = 1. if weight is None else weight[target].to(pred.dtype)\n    return (weight * (pred - target.to(pred.dtype)).pow(2)).mean()\n\n\nclass GNNEncoder(torch.nn.Module):\n    def __init__(self, hidden_channels, out_channels):\n        super().__init__()\n        self.conv1 = SAGEConv((-1, -1), hidden_channels)\n        self.conv2 = SAGEConv((-1, -1), out_channels)\n\n    def forward(self, x, edge_index):\n        x = self.conv1(x, edge_index).relu()\n        x = self.conv2(x, edge_index)\n        return x\n\n\nclass EdgeDecoder(torch.nn.Module):\n    def __init__(self, hidden_channels):\n        super().__init__()\n        self.lin1 = Linear(2 * hidden_channels, hidden_channels)\n        self.lin2 = Linear(hidden_channels, 1)\n\n    def forward(self, z_dict, edge_label_index):\n        row, col = edge_label_index\n        z = torch.cat([z_dict['user'][row], z_dict['movie'][col]], dim=-1)\n\n        z = self.lin1(z).relu()\n        z = self.lin2(z)\n        return z.view(-1)\n\n\nclass Model(torch.nn.Module):\n    def __init__(self, hidden_channels):\n        super().__init__()\n        self.encoder = GNNEncoder(hidden_channels, hidden_channels)\n        self.encoder = to_hetero(self.encoder, data.metadata(), aggr='sum')\n        self.decoder = EdgeDecoder(hidden_channels)\n\n    def forward(self, x_dict, edge_index_dict, edge_label_index):\n        z_dict = self.encoder(x_dict, edge_index_dict)\n        return self.decoder(z_dict, edge_label_index)\n\n\n\ndef train(model, optimizer):\n    model.train()\n    optimizer.zero_grad()\n    pred = model(train_data.x_dict, train_data.edge_index_dict,\n                 train_data['user', 'movie'].edge_label_index)\n    target = train_data['user', 'movie'].edge_label\n    loss = weighted_mse_loss(pred, target, weight)\n    loss.backward()\n    optimizer.step()\n    return float(loss)\n\n\n@torch.no_grad()\ndef test(data, model):\n    model.eval()\n    pred = model(data.x_dict, data.edge_index_dict,\n                 data['user', 'movie'].edge_label_index)\n    pred = pred.clamp(min=0, max=5)\n    target = data['user', 'movie'].edge_label.float()\n    rmse = F.mse_loss(pred, target).sqrt()\n    return float(rmse)","metadata":{"id":"YNw0WPkl0jai","execution":{"iopub.status.busy":"2023-12-16T13:44:10.570634Z","iopub.execute_input":"2023-12-16T13:44:10.571417Z","iopub.status.idle":"2023-12-16T13:44:10.587275Z","shell.execute_reply.started":"2023-12-16T13:44:10.571381Z","shell.execute_reply":"2023-12-16T13:44:10.586346Z"},"trusted":true},"execution_count":64,"outputs":[]},{"cell_type":"code","source":"from tqdm.notebook import tqdm\n\ndef start_train(model, optimizer, max_epochs = 300, print_each = 100):\n    for epoch in tqdm(range(1, max_epochs)):\n        loss = train(model, optimizer)\n        train_rmse = test(train_data, model)\n        val_rmse = test(val_data, model)\n        test_rmse = test(test_data, model)\n        if epoch % print_each == 0 or (epoch + 1) == max_epochs:\n            print(f'Epoch: {epoch:03d}, Loss: {loss:.4f}, Train: {train_rmse:.4f}, '\n                  f'Val: {val_rmse:.4f}, Test: {test_rmse:.4f}')","metadata":{"id":"QApxL66H7EyY","execution":{"iopub.status.busy":"2023-12-16T13:44:13.013352Z","iopub.execute_input":"2023-12-16T13:44:13.013726Z","iopub.status.idle":"2023-12-16T13:44:13.020016Z","shell.execute_reply.started":"2023-12-16T13:44:13.013696Z","shell.execute_reply":"2023-12-16T13:44:13.019162Z"},"trusted":true},"execution_count":65,"outputs":[]},{"cell_type":"code","source":"model = Model(hidden_channels=32).to(device)\noptimizer = torch.optim.Adam(model.parameters(), lr=0.01)","metadata":{"execution":{"iopub.status.busy":"2023-12-16T13:44:14.411977Z","iopub.execute_input":"2023-12-16T13:44:14.412354Z","iopub.status.idle":"2023-12-16T13:44:14.429261Z","shell.execute_reply.started":"2023-12-16T13:44:14.412325Z","shell.execute_reply":"2023-12-16T13:44:14.428370Z"},"trusted":true},"execution_count":66,"outputs":[]},{"cell_type":"code","source":"start_train(model, optimizer, max_epochs = 1000)","metadata":{"execution":{"iopub.status.busy":"2023-12-16T13:44:16.343999Z","iopub.execute_input":"2023-12-16T13:44:16.344675Z","iopub.status.idle":"2023-12-16T13:44:53.378790Z","shell.execute_reply.started":"2023-12-16T13:44:16.344642Z","shell.execute_reply":"2023-12-16T13:44:53.377849Z"},"trusted":true},"execution_count":67,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/999 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5cb7b4da3f304188b6c1aa7cfa0776ec"}},"metadata":{}},{"name":"stdout","text":"Epoch: 100, Loss: 3.0476, Train: 1.1063, Val: 1.1588, Test: 1.1545\nEpoch: 200, Loss: 2.7512, Train: 1.0798, Val: 1.1511, Test: 1.1397\nEpoch: 300, Loss: 2.4549, Train: 1.0207, Val: 1.1275, Test: 1.1134\nEpoch: 400, Loss: 2.2115, Train: 0.9774, Val: 1.1168, Test: 1.0958\nEpoch: 500, Loss: 2.9173, Train: 1.0834, Val: 1.2190, Test: 1.1995\nEpoch: 600, Loss: 1.9695, Train: 0.9530, Val: 1.1202, Test: 1.1014\nEpoch: 700, Loss: 2.3099, Train: 0.9664, Val: 1.1058, Test: 1.0944\nEpoch: 800, Loss: 1.7179, Train: 0.9092, Val: 1.1086, Test: 1.0901\nEpoch: 900, Loss: 1.6334, Train: 0.8843, Val: 1.0958, Test: 1.0806\nEpoch: 999, Loss: 1.6002, Train: 0.8882, Val: 1.1057, Test: 1.0939\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Вообще наблюдаем, что test loss не прям стабильно понижается, но иногда преодолевает порог в 1.1\n# Попробуем улучшить модель","metadata":{}},{"cell_type":"markdown","source":"## Задание\n\n## 1) Подберите оптимальные параметры для сети из примера выше(2 балла)\n","metadata":{"id":"uCuIyDT57GoX"}},{"cell_type":"code","source":"class GNNEncoderV2(torch.nn.Module):\n    def __init__(self, hidden_channels, out_channels, num_layers=1):\n        super().__init__()\n        self.conv_in = SAGEConv((-1, -1), hidden_channels)\n        self.conv_layers = torch.nn.ModuleList([\n            SAGEConv((-1, -1), hidden_channels // 2) for _ in range(num_layers)\n        ])\n        self.conv_out = SAGEConv((-1, -1), out_channels)\n\n    def forward(self, x, edge_index):\n        x = self.conv_in(x, edge_index).relu()\n        \n        for conv_layer in self.conv_layers:\n            x = conv_layer(x, edge_index).relu()\n    \n        x = self.conv_out(x, edge_index)\n        return x\n\n    \n# Первый слой - Linear\nclass EdgeDecoderV2(torch.nn.Module):\n    def __init__(self, hidden_channels, num_lin_layers=1, num_conv_layers=1):\n        super().__init__()\n        self.lin_in = Linear(2 * hidden_channels, hidden_channels)\n        \n        self.conv_layers = torch.nn.ModuleList([\n            GCNConv(hidden_channels, hidden_channels) for _ in range(num_conv_layers)\n        ])\n        \n        self.lin_layers = torch.nn.ModuleList([\n            Linear(hidden_channels, hidden_channels) for _ in range(num_lin_layers)\n        ])\n        \n        self.lin_out = Linear(hidden_channels, 1)\n\n    def forward(self, z_dict, edge_label_index):\n        row, col = edge_label_index\n        z = torch.cat([z_dict['user'][row], z_dict['movie'][col]], dim=-1)\n\n        z = self.lin_in(z).relu()\n        \n        for conv_layer in self.conv_layers:\n            z = conv_layer(z, edge_index=edge_label_index).relu()\n        \n        for lin_layer in self.lin_layers:\n            z = lin_layer(z).relu()\n            \n        z = self.lin_out(z)\n        return z.view(-1)\n\n# Первый слой - GCN\nclass EdgeDecoderV3(torch.nn.Module):\n    def __init__(self, hidden_channels, num_lin_layers=1, num_conv_layers=2):\n        super().__init__()\n        self.graph_conv = GCNConv(2 * hidden_channels, hidden_channels)\n        \n        self.conv_layers = torch.nn.ModuleList([\n            GCNConv(hidden_channels, hidden_channels) for _ in range(num_conv_layers)\n        ])\n        \n        self.lin_layers = torch.nn.ModuleList([\n            Linear(hidden_channels, hidden_channels) for _ in range(num_lin_layers)\n        ])\n        \n        self.lin_out = Linear(hidden_channels, 1)\n\n    def forward(self, z_dict, edge_label_index):\n        row, col = edge_label_index\n        z = torch.cat([z_dict['user'][row], z_dict['movie'][col]], dim=-1)\n\n        z = self.graph_conv(z, edge_index=edge_label_index).relu()\n\n        for conv_layer in self.conv_layers:\n            z = conv_layer(z, edge_index=edge_label_index).relu()\n        \n        for lin_layer in self.lin_layers:\n            z = lin_layer(z).relu()\n            \n        z = self.lin_out(z)\n        return z.view(-1)\n\n    \nclass EdgeDecoderV4(torch.nn.Module):\n    def __init__(self, hidden_channels):\n        super().__init__()\n        self.lin_in = Linear(2 * hidden_channels, hidden_channels)\n        \n        self.lin_layers = torch.nn.ModuleList([\n            Linear(hidden_channels, hidden_channels // 2),\n            Linear(hidden_channels // 2, hidden_channels // 4),\n            Linear(hidden_channels // 4, hidden_channels // 8),\n        ])\n        \n        self.lin_out = Linear(hidden_channels // 8, 1)\n\n    def forward(self, z_dict, edge_label_index):\n        row, col = edge_label_index\n        z = torch.cat([z_dict['user'][row], z_dict['movie'][col]], dim=-1)\n\n        z = self.lin_in(z).relu()\n        \n        for lin_layer in self.lin_layers:\n            z = lin_layer(z).relu()\n            \n        z = self.lin_out(z)\n        return z.view(-1)\n\n\nclass ModelV2(torch.nn.Module):\n    def __init__(self, hidden_channels, encoder_layers=1, decoder_ll=1, decoder_cl=1):\n        super().__init__()\n        self.encoder = GNNEncoderV2(hidden_channels, hidden_channels, num_layers=encoder_layers)\n\n        self.encoder = to_hetero(self.encoder, data.metadata(), aggr='sum')\n\n#         self.decoder = EdgeDecoderV2(hidden_channels, num_lin_layers=decoder_ll, num_conv_layers=decoder_cl)\n#         self.decoder = EdgeDecoderV3(hidden_channels, num_lin_layers=decoder_ll, num_conv_layers=decoder_cl)\n        self.decoder = EdgeDecoderV4(hidden_channels)\n\n    def forward(self, x_dict, edge_index_dict, edge_label_index):\n        z_dict = self.encoder(x_dict, edge_index_dict)\n        return self.decoder(z_dict, edge_label_index)\n","metadata":{"execution":{"iopub.status.busy":"2023-12-16T15:38:18.432336Z","iopub.execute_input":"2023-12-16T15:38:18.433134Z","iopub.status.idle":"2023-12-16T15:38:18.457722Z","shell.execute_reply.started":"2023-12-16T15:38:18.433102Z","shell.execute_reply":"2023-12-16T15:38:18.456783Z"},"trusted":true},"execution_count":272,"outputs":[]},{"cell_type":"code","source":"model_v2 = ModelV2(hidden_channels=128, encoder_layers=0, decoder_ll=0, decoder_cl=0).to(device)\noptimizerV2 = torch.optim.Adam(model_v2.parameters(), lr=0.005)","metadata":{"execution":{"iopub.status.busy":"2023-12-16T14:53:23.288237Z","iopub.execute_input":"2023-12-16T14:53:23.289277Z","iopub.status.idle":"2023-12-16T14:53:23.307748Z","shell.execute_reply.started":"2023-12-16T14:53:23.289227Z","shell.execute_reply":"2023-12-16T14:53:23.307010Z"},"trusted":true},"execution_count":241,"outputs":[]},{"cell_type":"code","source":"model_v2","metadata":{"execution":{"iopub.status.busy":"2023-12-16T14:50:41.818534Z","iopub.execute_input":"2023-12-16T14:50:41.818905Z","iopub.status.idle":"2023-12-16T14:50:41.825103Z","shell.execute_reply.started":"2023-12-16T14:50:41.818875Z","shell.execute_reply":"2023-12-16T14:50:41.824174Z"},"trusted":true},"execution_count":236,"outputs":[{"execution_count":236,"output_type":"execute_result","data":{"text/plain":"ModelV2(\n  (encoder): GraphModule(\n    (conv_in): ModuleDict(\n      (user__rates__movie): SAGEConv((-1, -1), 128, aggr=mean)\n      (movie__rev_rates__user): SAGEConv((-1, -1), 128, aggr=mean)\n    )\n    (conv_layers): ModuleList(\n      (0): ModuleDict(\n        (user__rates__movie): SAGEConv((-1, -1), 128, aggr=mean)\n        (movie__rev_rates__user): SAGEConv((-1, -1), 128, aggr=mean)\n      )\n    )\n    (conv_out): ModuleDict(\n      (user__rates__movie): SAGEConv((-1, -1), 128, aggr=mean)\n      (movie__rev_rates__user): SAGEConv((-1, -1), 128, aggr=mean)\n    )\n  )\n  (decoder): EdgeDecoderV4(\n    (lin_in): Linear(in_features=256, out_features=128, bias=True)\n    (lin_layers): ModuleList(\n      (0): Linear(in_features=128, out_features=64, bias=True)\n      (1): Linear(in_features=64, out_features=32, bias=True)\n    )\n    (lin_out): Linear(in_features=32, out_features=1, bias=True)\n  )\n)"},"metadata":{}}]},{"cell_type":"code","source":"# input 64\nstart_train(model_v2, optimizerV2, max_epochs = 1000, print_each = 100)","metadata":{"execution":{"iopub.status.busy":"2023-12-16T14:46:55.397079Z","iopub.execute_input":"2023-12-16T14:46:55.397732Z","iopub.status.idle":"2023-12-16T14:47:39.077983Z","shell.execute_reply.started":"2023-12-16T14:46:55.397701Z","shell.execute_reply":"2023-12-16T14:47:39.077052Z"},"trusted":true},"execution_count":229,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/999 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c93ee8dabb5149a881abd01978e74527"}},"metadata":{}},{"name":"stdout","text":"Epoch: 100, Loss: 2.9585, Train: 1.1052, Val: 1.1633, Test: 1.1580\nEpoch: 200, Loss: 2.4466, Train: 1.0120, Val: 1.1259, Test: 1.1070\nEpoch: 300, Loss: 2.0791, Train: 0.9673, Val: 1.1099, Test: 1.0993\nEpoch: 400, Loss: 1.8877, Train: 0.9285, Val: 1.1028, Test: 1.0890\nEpoch: 500, Loss: 1.7203, Train: 0.8969, Val: 1.0955, Test: 1.0801\nEpoch: 600, Loss: 1.6496, Train: 0.8796, Val: 1.1062, Test: 1.0887\nEpoch: 700, Loss: 1.3921, Train: 0.8452, Val: 1.1122, Test: 1.0979\nEpoch: 800, Loss: 1.3222, Train: 0.8148, Val: 1.1070, Test: 1.0948\nEpoch: 900, Loss: 1.2976, Train: 0.7918, Val: 1.1124, Test: 1.1013\nEpoch: 999, Loss: 1.1384, Train: 0.8109, Val: 1.1280, Test: 1.1184\n","output_type":"stream"}]},{"cell_type":"code","source":"# input 128\nstart_train(model_v2, optimizerV2, max_epochs = 1000, print_each = 100)","metadata":{"execution":{"iopub.status.busy":"2023-12-16T14:48:57.114317Z","iopub.execute_input":"2023-12-16T14:48:57.115192Z","iopub.status.idle":"2023-12-16T14:49:51.571864Z","shell.execute_reply.started":"2023-12-16T14:48:57.115159Z","shell.execute_reply":"2023-12-16T14:49:51.570950Z"},"trusted":true},"execution_count":232,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/999 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"012b2a40295b4cf39157ae7a05f47d08"}},"metadata":{}},{"name":"stdout","text":"Epoch: 100, Loss: 2.7383, Train: 1.0955, Val: 1.1787, Test: 1.1664\nEpoch: 200, Loss: 2.2472, Train: 1.0176, Val: 1.1483, Test: 1.1381\nEpoch: 300, Loss: 2.0004, Train: 0.9223, Val: 1.0848, Test: 1.0726\nEpoch: 400, Loss: 1.8706, Train: 0.9106, Val: 1.0954, Test: 1.0964\nEpoch: 500, Loss: 1.6910, Train: 0.8569, Val: 1.0745, Test: 1.0805\nEpoch: 600, Loss: 1.4754, Train: 0.8412, Val: 1.0892, Test: 1.0841\nEpoch: 700, Loss: 1.3358, Train: 0.8325, Val: 1.1008, Test: 1.0961\nEpoch: 800, Loss: 1.3336, Train: 0.7987, Val: 1.0738, Test: 1.0732\nEpoch: 900, Loss: 1.1824, Train: 0.7801, Val: 1.1000, Test: 1.0989\nEpoch: 999, Loss: 1.0763, Train: 0.7543, Val: 1.0985, Test: 1.1007\n","output_type":"stream"}]},{"cell_type":"code","source":"# input 128 encoder layers 0\nmodel_v2 = ModelV2(hidden_channels=128, encoder_layers=0, decoder_ll=0, decoder_cl=0).to(device)\noptimizerV2 = torch.optim.Adam(model_v2.parameters(), lr=0.005)\nstart_train(model_v2, optimizerV2, max_epochs = 1000, print_each = 100)","metadata":{"execution":{"iopub.status.busy":"2023-12-16T14:53:30.064258Z","iopub.execute_input":"2023-12-16T14:53:30.064974Z","iopub.status.idle":"2023-12-16T14:54:24.415639Z","shell.execute_reply.started":"2023-12-16T14:53:30.064943Z","shell.execute_reply":"2023-12-16T14:54:24.414717Z"},"trusted":true},"execution_count":242,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/999 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3739690745e746749d631b38bc45c825"}},"metadata":{}},{"name":"stdout","text":"Epoch: 100, Loss: 3.1194, Train: 1.1066, Val: 1.1512, Test: 1.1466\nEpoch: 200, Loss: 2.3580, Train: 1.0061, Val: 1.1300, Test: 1.1120\nEpoch: 300, Loss: 1.9621, Train: 0.9381, Val: 1.0894, Test: 1.0628\nEpoch: 400, Loss: 1.7678, Train: 0.9079, Val: 1.0839, Test: 1.0584\nEpoch: 500, Loss: 1.6540, Train: 0.8733, Val: 1.0672, Test: 1.0491\nEpoch: 600, Loss: 1.4914, Train: 0.8514, Val: 1.0881, Test: 1.0764\nEpoch: 700, Loss: 1.4342, Train: 0.8292, Val: 1.0962, Test: 1.0783\nEpoch: 800, Loss: 1.3005, Train: 0.8085, Val: 1.0985, Test: 1.0769\nEpoch: 900, Loss: 1.1718, Train: 0.7882, Val: 1.1130, Test: 1.0945\nEpoch: 999, Loss: 1.0787, Train: 0.7554, Val: 1.1131, Test: 1.0956\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### На 1000 эпохах лучший результат показала: ","metadata":{}},{"cell_type":"code","source":"# input 96 encoder layers 0 decoder layers 2\nmodel_v2 = ModelV2(hidden_channels=96, encoder_layers=0, decoder_ll=0, decoder_cl=0).to(device)\noptimizerV2 = torch.optim.Adam(model_v2.parameters(), lr=0.005)\nstart_train(model_v2, optimizerV2, max_epochs = 1000, print_each = 100)","metadata":{"execution":{"iopub.status.busy":"2023-12-16T14:57:23.967554Z","iopub.execute_input":"2023-12-16T14:57:23.968230Z","iopub.status.idle":"2023-12-16T14:58:14.467462Z","shell.execute_reply.started":"2023-12-16T14:57:23.968197Z","shell.execute_reply":"2023-12-16T14:58:14.466565Z"},"trusted":true},"execution_count":247,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/999 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"aacfe901380346b195752fa601f48aca"}},"metadata":{}},{"name":"stdout","text":"Epoch: 100, Loss: 3.0342, Train: 1.1059, Val: 1.1634, Test: 1.1591\nEpoch: 200, Loss: 2.3098, Train: 0.9891, Val: 1.1019, Test: 1.0912\nEpoch: 300, Loss: 2.0523, Train: 0.9406, Val: 1.0930, Test: 1.0796\nEpoch: 400, Loss: 1.8718, Train: 0.8983, Val: 1.0595, Test: 1.0470\nEpoch: 500, Loss: 1.7456, Train: 0.9007, Val: 1.0814, Test: 1.0700\nEpoch: 600, Loss: 1.6082, Train: 0.8687, Val: 1.0770, Test: 1.0638\nEpoch: 700, Loss: 1.4837, Train: 0.8425, Val: 1.0765, Test: 1.0682\nEpoch: 800, Loss: 1.5021, Train: 0.9385, Val: 1.1580, Test: 1.1443\nEpoch: 900, Loss: 1.3001, Train: 0.8083, Val: 1.0882, Test: 1.0733\nEpoch: 999, Loss: 1.2390, Train: 0.7851, Val: 1.0990, Test: 1.0774\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### Далее я еще немного попробовал большее число эпох, но основной score уже побит","metadata":{}},{"cell_type":"code","source":"# input 80 encoder layers 1 decoder layers 3\nmodel_v2 = ModelV2(hidden_channels=80, encoder_layers=1, decoder_ll=0, decoder_cl=0).to(device)\noptimizerV2 = torch.optim.Adam(model_v2.parameters(), lr=0.001)\nstart_train(model_v2, optimizerV2, max_epochs = 4000, print_each = 100)","metadata":{"execution":{"iopub.status.busy":"2023-12-16T15:23:13.789074Z","iopub.execute_input":"2023-12-16T15:23:13.789478Z","iopub.status.idle":"2023-12-16T15:26:48.179291Z","shell.execute_reply.started":"2023-12-16T15:23:13.789450Z","shell.execute_reply":"2023-12-16T15:26:48.178334Z"},"trusted":true},"execution_count":267,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/3999 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"84d174fed3e34d53b1c8148f3321edf4"}},"metadata":{}},{"name":"stdout","text":"Epoch: 100, Loss: 5.2165, Train: 1.2565, Val: 1.2872, Test: 1.2819\nEpoch: 200, Loss: 2.9737, Train: 1.0959, Val: 1.1553, Test: 1.1493\nEpoch: 300, Loss: 2.4490, Train: 1.0397, Val: 1.1444, Test: 1.1282\nEpoch: 400, Loss: 2.2429, Train: 0.9686, Val: 1.0985, Test: 1.0844\nEpoch: 500, Loss: 2.0847, Train: 0.9877, Val: 1.1295, Test: 1.1181\nEpoch: 600, Loss: 2.0025, Train: 0.9405, Val: 1.1012, Test: 1.0900\nEpoch: 700, Loss: 1.8244, Train: 0.8856, Val: 1.0615, Test: 1.0543\nEpoch: 800, Loss: 1.8191, Train: 0.9253, Val: 1.1158, Test: 1.1022\nEpoch: 900, Loss: 1.7026, Train: 0.8794, Val: 1.0812, Test: 1.0651\nEpoch: 1000, Loss: 1.6591, Train: 0.8868, Val: 1.0838, Test: 1.0641\nEpoch: 1100, Loss: 1.6056, Train: 0.8863, Val: 1.1033, Test: 1.0763\nEpoch: 1200, Loss: 1.5557, Train: 0.8462, Val: 1.0659, Test: 1.0438\nEpoch: 1300, Loss: 1.5322, Train: 0.8518, Val: 1.0821, Test: 1.0583\nEpoch: 1400, Loss: 1.5066, Train: 0.8420, Val: 1.0745, Test: 1.0515\nEpoch: 1500, Loss: 1.5244, Train: 0.8568, Val: 1.0904, Test: 1.0711\nEpoch: 1600, Loss: 1.4819, Train: 0.8258, Val: 1.0681, Test: 1.0411\nEpoch: 1700, Loss: 1.6229, Train: 0.8263, Val: 1.0694, Test: 1.0452\nEpoch: 1800, Loss: 1.4569, Train: 0.8156, Val: 1.0615, Test: 1.0379\nEpoch: 1900, Loss: 1.4493, Train: 0.8330, Val: 1.0799, Test: 1.0515\nEpoch: 2000, Loss: 1.4029, Train: 0.8222, Val: 1.0828, Test: 1.0557\nEpoch: 2100, Loss: 1.3712, Train: 0.8146, Val: 1.0828, Test: 1.0536\nEpoch: 2200, Loss: 1.4017, Train: 0.8153, Val: 1.0779, Test: 1.0555\nEpoch: 2300, Loss: 1.3859, Train: 0.8285, Val: 1.1018, Test: 1.0734\nEpoch: 2400, Loss: 1.3218, Train: 0.8018, Val: 1.0810, Test: 1.0543\nEpoch: 2500, Loss: 1.3122, Train: 0.7962, Val: 1.0761, Test: 1.0510\nEpoch: 2600, Loss: 1.3151, Train: 0.8000, Val: 1.0719, Test: 1.0516\nEpoch: 2700, Loss: 1.2780, Train: 0.7921, Val: 1.0846, Test: 1.0648\nEpoch: 2800, Loss: 1.2676, Train: 0.7954, Val: 1.0980, Test: 1.0741\nEpoch: 2900, Loss: 1.2515, Train: 0.7792, Val: 1.0835, Test: 1.0627\nEpoch: 3000, Loss: 1.2317, Train: 0.7776, Val: 1.0892, Test: 1.0677\nEpoch: 3100, Loss: 1.2150, Train: 0.7758, Val: 1.0913, Test: 1.0715\nEpoch: 3200, Loss: 1.3538, Train: 0.7887, Val: 1.0888, Test: 1.0647\nEpoch: 3300, Loss: 1.1749, Train: 0.7697, Val: 1.1005, Test: 1.0774\nEpoch: 3400, Loss: 1.1595, Train: 0.7685, Val: 1.1032, Test: 1.0776\nEpoch: 3500, Loss: 1.1866, Train: 0.7663, Val: 1.1065, Test: 1.0851\nEpoch: 3600, Loss: 1.1507, Train: 0.7678, Val: 1.1126, Test: 1.0875\nEpoch: 3700, Loss: 1.2500, Train: 0.7915, Val: 1.1393, Test: 1.1149\nEpoch: 3800, Loss: 1.1318, Train: 0.7525, Val: 1.1110, Test: 1.0873\nEpoch: 3900, Loss: 1.0972, Train: 0.7501, Val: 1.1104, Test: 1.0878\nEpoch: 3999, Loss: 1.2172, Train: 0.7573, Val: 1.1183, Test: 1.0930\n","output_type":"stream"}]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"# input 128 encoder layers 0 decoder layers 3\nmodel_v2 = ModelV2(hidden_channels=128, encoder_layers=2, decoder_ll=0, decoder_cl=0).to(device)\noptimizerV2 = torch.optim.Adam(model_v2.parameters(), lr=0.001)\nstart_train(model_v2, optimizerV2, max_epochs = 6000, print_each = 100)","metadata":{"execution":{"iopub.status.busy":"2023-12-16T15:38:30.269135Z","iopub.execute_input":"2023-12-16T15:38:30.269866Z","iopub.status.idle":"2023-12-16T15:45:08.118851Z","shell.execute_reply.started":"2023-12-16T15:38:30.269814Z","shell.execute_reply":"2023-12-16T15:45:08.117877Z"},"trusted":true},"execution_count":273,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/5999 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cb15629420624cbab48a4cbbdc928c62"}},"metadata":{}},{"name":"stdout","text":"Epoch: 100, Loss: 5.2856, Train: 1.2512, Val: 1.2874, Test: 1.2817\nEpoch: 200, Loss: 2.7913, Train: 1.1063, Val: 1.1897, Test: 1.1809\nEpoch: 300, Loss: 2.2810, Train: 0.9841, Val: 1.1187, Test: 1.0972\nEpoch: 400, Loss: 2.1297, Train: 1.0140, Val: 1.1727, Test: 1.1529\nEpoch: 500, Loss: 2.0481, Train: 0.9475, Val: 1.1168, Test: 1.0983\nEpoch: 600, Loss: 2.0402, Train: 0.9638, Val: 1.1342, Test: 1.1172\nEpoch: 700, Loss: 1.9801, Train: 0.9332, Val: 1.1184, Test: 1.0972\nEpoch: 800, Loss: 1.8620, Train: 0.9364, Val: 1.1285, Test: 1.1074\nEpoch: 900, Loss: 1.8157, Train: 0.9198, Val: 1.1187, Test: 1.0950\nEpoch: 1000, Loss: 1.8248, Train: 0.9170, Val: 1.1291, Test: 1.1011\nEpoch: 1100, Loss: 1.8329, Train: 0.8997, Val: 1.1065, Test: 1.0740\nEpoch: 1200, Loss: 1.6901, Train: 0.8921, Val: 1.1260, Test: 1.0854\nEpoch: 1300, Loss: 1.7004, Train: 0.8947, Val: 1.1258, Test: 1.0923\nEpoch: 1400, Loss: 1.6393, Train: 0.8807, Val: 1.1236, Test: 1.0920\nEpoch: 1500, Loss: 1.6022, Train: 0.8874, Val: 1.1412, Test: 1.1089\nEpoch: 1600, Loss: 1.5576, Train: 0.8558, Val: 1.1198, Test: 1.0848\nEpoch: 1700, Loss: 1.5469, Train: 0.8641, Val: 1.1313, Test: 1.0957\nEpoch: 1800, Loss: 1.5287, Train: 0.8826, Val: 1.1484, Test: 1.1176\nEpoch: 1900, Loss: 1.4667, Train: 0.8571, Val: 1.1391, Test: 1.1095\nEpoch: 2000, Loss: 1.4842, Train: 0.8686, Val: 1.1425, Test: 1.1092\nEpoch: 2100, Loss: 1.4263, Train: 0.8341, Val: 1.1279, Test: 1.0936\nEpoch: 2200, Loss: 1.4072, Train: 0.8343, Val: 1.1314, Test: 1.0978\nEpoch: 2300, Loss: 1.3916, Train: 0.8174, Val: 1.1263, Test: 1.0908\nEpoch: 2400, Loss: 1.4062, Train: 0.8333, Val: 1.1366, Test: 1.0958\nEpoch: 2500, Loss: 1.5089, Train: 0.8732, Val: 1.1289, Test: 1.0981\nEpoch: 2600, Loss: 1.7204, Train: 0.9727, Val: 1.2286, Test: 1.2009\nEpoch: 2700, Loss: 1.2944, Train: 0.7947, Val: 1.1259, Test: 1.0926\nEpoch: 2800, Loss: 1.2932, Train: 0.7978, Val: 1.1286, Test: 1.0947\nEpoch: 2900, Loss: 1.2586, Train: 0.7925, Val: 1.1305, Test: 1.1006\nEpoch: 3000, Loss: 1.2933, Train: 0.8088, Val: 1.1272, Test: 1.0977\nEpoch: 3100, Loss: 1.2372, Train: 0.7848, Val: 1.1246, Test: 1.0986\nEpoch: 3200, Loss: 1.4134, Train: 0.8436, Val: 1.1510, Test: 1.1245\nEpoch: 3300, Loss: 1.2208, Train: 0.7875, Val: 1.1362, Test: 1.1061\nEpoch: 3400, Loss: 1.1935, Train: 0.7820, Val: 1.1372, Test: 1.1069\nEpoch: 3500, Loss: 1.1885, Train: 0.7786, Val: 1.1368, Test: 1.1092\nEpoch: 3600, Loss: 1.1805, Train: 0.7701, Val: 1.1320, Test: 1.1056\nEpoch: 3700, Loss: 1.1697, Train: 0.7676, Val: 1.1395, Test: 1.1144\nEpoch: 3800, Loss: 1.1646, Train: 0.7639, Val: 1.1327, Test: 1.1054\nEpoch: 3900, Loss: 1.1530, Train: 0.7635, Val: 1.1374, Test: 1.1145\nEpoch: 4000, Loss: 1.1428, Train: 0.7599, Val: 1.1329, Test: 1.1077\nEpoch: 4100, Loss: 1.1792, Train: 0.7893, Val: 1.1501, Test: 1.1287\nEpoch: 4200, Loss: 1.1177, Train: 0.7593, Val: 1.1383, Test: 1.1137\nEpoch: 4300, Loss: 1.2162, Train: 0.8042, Val: 1.1618, Test: 1.1404\nEpoch: 4400, Loss: 1.0839, Train: 0.7473, Val: 1.1391, Test: 1.1134\nEpoch: 4500, Loss: 1.1027, Train: 0.7630, Val: 1.1443, Test: 1.1204\nEpoch: 4600, Loss: 1.1082, Train: 0.7429, Val: 1.1405, Test: 1.1154\nEpoch: 4700, Loss: 1.0930, Train: 0.7550, Val: 1.1559, Test: 1.1271\nEpoch: 4800, Loss: 1.1310, Train: 0.7415, Val: 1.1436, Test: 1.1163\nEpoch: 4900, Loss: 1.0673, Train: 0.7374, Val: 1.1438, Test: 1.1155\nEpoch: 5000, Loss: 1.0415, Train: 0.7366, Val: 1.1438, Test: 1.1182\nEpoch: 5100, Loss: 1.1129, Train: 0.7493, Val: 1.1485, Test: 1.1212\nEpoch: 5200, Loss: 1.0237, Train: 0.7459, Val: 1.1488, Test: 1.1193\nEpoch: 5300, Loss: 1.0174, Train: 0.7330, Val: 1.1532, Test: 1.1258\nEpoch: 5400, Loss: 1.0259, Train: 0.7365, Val: 1.1558, Test: 1.1252\nEpoch: 5500, Loss: 1.0112, Train: 0.7297, Val: 1.1445, Test: 1.1195\nEpoch: 5600, Loss: 0.9834, Train: 0.7273, Val: 1.1511, Test: 1.1238\nEpoch: 5700, Loss: 0.9889, Train: 0.7383, Val: 1.1588, Test: 1.1342\nEpoch: 5800, Loss: 1.0469, Train: 0.7287, Val: 1.1513, Test: 1.1224\nEpoch: 5900, Loss: 0.9706, Train: 0.7192, Val: 1.1569, Test: 1.1277\nEpoch: 5999, Loss: 1.0223, Train: 0.7303, Val: 1.1633, Test: 1.1366\n","output_type":"stream"}]},{"cell_type":"code","source":"# input 128 encoder layers 0 decoder layers 3\nmodel_v2 = ModelV2(hidden_channels=156, encoder_layers=1, decoder_ll=0, decoder_cl=0).to(device)\noptimizerV2 = torch.optim.Adam(model_v2.parameters(), lr=0.001)\nstart_train(model_v2, optimizerV2, max_epochs = 3000, print_each = 100)","metadata":{"execution":{"iopub.status.busy":"2023-12-16T17:22:59.374554Z","iopub.execute_input":"2023-12-16T17:22:59.375322Z","iopub.status.idle":"2023-12-16T17:26:25.733559Z","shell.execute_reply.started":"2023-12-16T17:22:59.375284Z","shell.execute_reply":"2023-12-16T17:26:25.732529Z"},"trusted":true},"execution_count":372,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/2999 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"668f01ccae40448791b2a2441babcc35"}},"metadata":{}},{"name":"stdout","text":"Epoch: 100, Loss: 4.6173, Train: 1.1889, Val: 1.2254, Test: 1.2233\nEpoch: 200, Loss: 2.6606, Train: 1.0513, Val: 1.1366, Test: 1.1231\nEpoch: 300, Loss: 2.2676, Train: 0.9748, Val: 1.1092, Test: 1.0849\nEpoch: 400, Loss: 2.1035, Train: 0.9746, Val: 1.1239, Test: 1.1039\nEpoch: 500, Loss: 2.2131, Train: 0.9250, Val: 1.0824, Test: 1.0552\nEpoch: 600, Loss: 1.8998, Train: 0.9305, Val: 1.1061, Test: 1.0853\nEpoch: 700, Loss: 1.8720, Train: 0.9208, Val: 1.1114, Test: 1.0849\nEpoch: 800, Loss: 1.7413, Train: 0.8852, Val: 1.0941, Test: 1.0668\nEpoch: 900, Loss: 1.6860, Train: 0.9041, Val: 1.1226, Test: 1.0980\nEpoch: 1000, Loss: 1.5804, Train: 0.8757, Val: 1.1070, Test: 1.0840\nEpoch: 1100, Loss: 1.5403, Train: 0.8560, Val: 1.0951, Test: 1.0734\nEpoch: 1200, Loss: 1.5593, Train: 0.8651, Val: 1.0956, Test: 1.0772\nEpoch: 1300, Loss: 1.4749, Train: 0.8422, Val: 1.0979, Test: 1.0762\nEpoch: 1400, Loss: 1.4325, Train: 0.8362, Val: 1.1013, Test: 1.0773\nEpoch: 1500, Loss: 1.4031, Train: 0.8272, Val: 1.0958, Test: 1.0693\nEpoch: 1600, Loss: 1.3737, Train: 0.8120, Val: 1.0957, Test: 1.0655\nEpoch: 1700, Loss: 1.3380, Train: 0.8324, Val: 1.1234, Test: 1.0914\nEpoch: 1800, Loss: 1.2950, Train: 0.8016, Val: 1.1066, Test: 1.0719\nEpoch: 1900, Loss: 1.2979, Train: 0.7914, Val: 1.0966, Test: 1.0627\nEpoch: 2000, Loss: 1.2456, Train: 0.7918, Val: 1.1125, Test: 1.0808\nEpoch: 2100, Loss: 1.2132, Train: 0.7850, Val: 1.1093, Test: 1.0779\nEpoch: 2200, Loss: 1.1901, Train: 0.7787, Val: 1.1094, Test: 1.0795\nEpoch: 2300, Loss: 1.1532, Train: 0.7796, Val: 1.1204, Test: 1.0891\nEpoch: 2400, Loss: 1.1296, Train: 0.7637, Val: 1.1203, Test: 1.0861\nEpoch: 2500, Loss: 1.1208, Train: 0.7523, Val: 1.1128, Test: 1.0826\nEpoch: 2600, Loss: 1.2212, Train: 0.7634, Val: 1.1263, Test: 1.0948\nEpoch: 2700, Loss: 1.0749, Train: 0.7527, Val: 1.1307, Test: 1.1003\nEpoch: 2800, Loss: 1.0601, Train: 0.7412, Val: 1.1277, Test: 1.0978\nEpoch: 2900, Loss: 1.0480, Train: 0.7388, Val: 1.1332, Test: 1.1022\nEpoch: 2999, Loss: 1.0102, Train: 0.7311, Val: 1.1290, Test: 1.1026\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### По последнему заданию давайте считать, что задача найти архитектуру, для которой RMSE на тесте лучше 1.1\n### Задача была выполнена, показал разные модели","metadata":{}},{"cell_type":"code","source":"","metadata":{"id":"F1ZQhceb7HQa"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 2) Попробуйте вместо GraphSage модуль Graph Attention и также подберите оптимальные параметры  (2 балла)","metadata":{}},{"cell_type":"code","source":"import torch\nfrom torch_geometric.nn import GATConv, global_add_pool\nfrom torch.nn import Linear, Dropout\n\nclass GNNEncoderGAT(torch.nn.Module):\n    def __init__(self, hidden_channels, out_channels, heads=2, num_layers=1, dropout=0.5):\n        super().__init__()\n#         self.conv_in = GATConv((-1, -1), 16, heads=8, dropout=0.6, add_self_loops=False)\n#         self.conv_out = GATConv(16 * 8, out_channels, heads=1, concat=False, dropout=0.6, add_self_loops=False)\n        \n        self.conv_in = GATConv((-1, -1), hidden_channels, heads=heads, dropout=dropout, add_self_loops=False)\n        \n        self.gat_layers = torch.nn.ModuleList([\n            GATConv(hidden_channels * heads, hidden_channels, heads=heads, dropout=dropout, add_self_loops=False) for _ in range(num_layers)\n        ])\n        \n        self.conv_out = GATConv(hidden_channels * heads, out_channels, heads=1, dropout=dropout, add_self_loops=False)\n\n    def forward(self, x, edge_index):\n        \n        x = F.elu(self.conv_in(x, edge_index))\n        \n        for gat_layer in self.gat_layers:\n            x = F.elu(gat_layer(x, edge_index))\n\n        x = self.conv_out(x, edge_index)\n        return x\n\n\nclass EdgeDecoderGAT(torch.nn.Module):\n    def __init__(self, hidden_channels):\n        super().__init__()\n        self.lin_in = Linear(2 * hidden_channels, hidden_channels)\n        \n        self.lin_layers = torch.nn.ModuleList([\n            Linear(hidden_channels, hidden_channels // 2),\n            Linear(hidden_channels // 2, hidden_channels // 4),\n            Linear(hidden_channels // 4, hidden_channels // 8),\n        ])\n        \n        self.lin_out = Linear(hidden_channels // 8, 1)\n\n    def forward(self, z_dict, edge_label_index):\n        row, col = edge_label_index\n        z = torch.cat([z_dict['user'][row], z_dict['movie'][col]], dim=-1)\n\n        z = self.lin_in(z).relu()\n        \n        for lin_layer in self.lin_layers:\n            z = lin_layer(z).relu()\n            \n        z = self.lin_out(z)\n        return z.view(-1)\n\n\nclass ModelGAT(torch.nn.Module):\n    def __init__(self, hidden_channels, encoder_layers=1, heads=1):\n        super().__init__()\n        self.encoder = GNNEncoderGAT(hidden_channels, hidden_channels, num_layers=encoder_layers, heads=heads)\n        self.encoder = to_hetero(self.encoder, data.metadata(), aggr='sum')\n        self.decoder = EdgeDecoderGAT(hidden_channels)\n\n    def forward(self, x_dict, edge_index_dict, edge_label_index):\n        z_dict = self.encoder(x_dict, edge_index_dict)\n        return self.decoder(z_dict, edge_label_index)","metadata":{"execution":{"iopub.status.busy":"2023-12-16T18:05:32.540307Z","iopub.execute_input":"2023-12-16T18:05:32.540677Z","iopub.status.idle":"2023-12-16T18:05:32.555791Z","shell.execute_reply.started":"2023-12-16T18:05:32.540647Z","shell.execute_reply":"2023-12-16T18:05:32.554764Z"},"trusted":true},"execution_count":454,"outputs":[]},{"cell_type":"code","source":"model_gat","metadata":{"execution":{"iopub.status.busy":"2023-12-16T18:01:03.927279Z","iopub.execute_input":"2023-12-16T18:01:03.928160Z","iopub.status.idle":"2023-12-16T18:01:03.934333Z","shell.execute_reply.started":"2023-12-16T18:01:03.928128Z","shell.execute_reply":"2023-12-16T18:01:03.933315Z"},"trusted":true},"execution_count":446,"outputs":[{"execution_count":446,"output_type":"execute_result","data":{"text/plain":"ModelGAT(\n  (encoder): GraphModule(\n    (conv_in): ModuleDict(\n      (user__rates__movie): GATConv((-1, -1), 16, heads=8)\n      (movie__rev_rates__user): GATConv((-1, -1), 16, heads=8)\n    )\n    (conv_out): ModuleDict(\n      (user__rates__movie): GATConv(128, 64, heads=1)\n      (movie__rev_rates__user): GATConv(128, 64, heads=1)\n    )\n  )\n  (decoder): EdgeDecoderGAT(\n    (lin_in): Linear(in_features=128, out_features=64, bias=True)\n    (lin_layers): ModuleList(\n      (0): Linear(in_features=64, out_features=32, bias=True)\n      (1): Linear(in_features=32, out_features=16, bias=True)\n      (2): Linear(in_features=16, out_features=8, bias=True)\n    )\n    (lin_out): Linear(in_features=8, out_features=1, bias=True)\n  )\n)"},"metadata":{}}]},{"cell_type":"code","source":"model_gat = ModelGAT(hidden_channels=32, encoder_layers=4, heads=8).to(device)\noptimizer_gat = torch.optim.Adam(model_gat.parameters(), lr=0.005)\n\nstart_train(model_gat, optimizer_gat, max_epochs=1000, print_each=100)","metadata":{"execution":{"iopub.status.busy":"2023-12-16T18:29:29.426501Z","iopub.execute_input":"2023-12-16T18:29:29.427242Z","iopub.status.idle":"2023-12-16T18:32:13.471428Z","shell.execute_reply.started":"2023-12-16T18:29:29.427211Z","shell.execute_reply":"2023-12-16T18:32:13.470444Z"},"trusted":true},"execution_count":472,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/999 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"53342c7309ca401bb46bd82008920044"}},"metadata":{}},{"name":"stdout","text":"Epoch: 100, Loss: 13.0386, Train: 2.8690, Val: 2.8733, Test: 2.8580\nEpoch: 200, Loss: 10.1961, Train: 2.4840, Val: 2.4888, Test: 2.4736\nEpoch: 300, Loss: 8.3717, Train: 2.1677, Val: 2.1731, Test: 2.1581\nEpoch: 400, Loss: 7.2810, Train: 1.9195, Val: 1.9255, Test: 1.9108\nEpoch: 500, Loss: 6.6799, Train: 1.7344, Val: 1.7409, Test: 1.7267\nEpoch: 600, Loss: 6.3772, Train: 1.6035, Val: 1.6105, Test: 1.5966\nEpoch: 700, Loss: 6.2390, Train: 1.5155, Val: 1.5229, Test: 1.5094\nEpoch: 800, Loss: 6.1820, Train: 1.4591, Val: 1.4667, Test: 1.4535\nEpoch: 900, Loss: 6.1609, Train: 1.4246, Val: 1.4323, Test: 1.4194\nEpoch: 999, Loss: 6.1540, Train: 1.4046, Val: 1.4124, Test: 1.3996\n","output_type":"stream"}]},{"cell_type":"code","source":"model_gat = ModelGAT(hidden_channels=64, encoder_layers=0, heads=4).to(device)\noptimizer_gat = torch.optim.Adam(model_gat.parameters(), lr=0.001)\n\nstart_train(model_gat, optimizer_gat, max_epochs=1000, print_each=100)","metadata":{"execution":{"iopub.status.busy":"2023-12-16T18:09:04.129949Z","iopub.execute_input":"2023-12-16T18:09:04.130247Z","iopub.status.idle":"2023-12-16T18:09:51.753106Z","shell.execute_reply.started":"2023-12-16T18:09:04.130220Z","shell.execute_reply":"2023-12-16T18:09:51.752118Z"},"trusted":true},"execution_count":458,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/999 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"95b368f871bf48f58166f49e7d9bf6ce"}},"metadata":{}},{"name":"stdout","text":"Epoch: 100, Loss: 5.7456, Train: 1.3447, Val: 1.3637, Test: 1.3542\nEpoch: 200, Loss: 4.5827, Train: 1.1847, Val: 1.1941, Test: 1.1746\nEpoch: 300, Loss: 4.2765, Train: 1.1664, Val: 1.1807, Test: 1.1486\nEpoch: 400, Loss: 3.7082, Train: 1.1088, Val: 1.1315, Test: 1.1004\nEpoch: 500, Loss: 3.5132, Train: 1.1210, Val: 1.1488, Test: 1.1216\nEpoch: 600, Loss: 3.4676, Train: 1.0914, Val: 1.1254, Test: 1.0990\nEpoch: 700, Loss: 3.3377, Train: 1.1338, Val: 1.1695, Test: 1.1417\nEpoch: 800, Loss: 3.2313, Train: 1.0558, Val: 1.0931, Test: 1.0704\nEpoch: 900, Loss: 3.1017, Train: 1.0960, Val: 1.1290, Test: 1.1030\nEpoch: 999, Loss: 3.0239, Train: 1.0677, Val: 1.1080, Test: 1.0832\n","output_type":"stream"}]},{"cell_type":"code","source":"model_gat = ModelGAT(hidden_channels=64, encoder_layers=0, heads=4).to(device)\noptimizer_gat = torch.optim.Adam(model_gat.parameters(), lr=0.005)\n\nstart_train(model_gat, optimizer_gat, max_epochs=1000, print_each=100)","metadata":{"execution":{"iopub.status.busy":"2023-12-16T18:16:28.318281Z","iopub.execute_input":"2023-12-16T18:16:28.318619Z","iopub.status.idle":"2023-12-16T18:17:16.128240Z","shell.execute_reply.started":"2023-12-16T18:16:28.318594Z","shell.execute_reply":"2023-12-16T18:17:16.127346Z"},"trusted":true},"execution_count":463,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/999 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"28900479f64d428d8881f1a5bede7806"}},"metadata":{}},{"name":"stdout","text":"Epoch: 100, Loss: 4.6188, Train: 1.1809, Val: 1.1932, Test: 1.1696\nEpoch: 200, Loss: 3.7479, Train: 1.1332, Val: 1.1551, Test: 1.1239\nEpoch: 300, Loss: 3.5496, Train: 1.1015, Val: 1.1305, Test: 1.1047\nEpoch: 400, Loss: 3.5314, Train: 1.0580, Val: 1.0949, Test: 1.0757\nEpoch: 500, Loss: 3.2825, Train: 1.0896, Val: 1.1280, Test: 1.1040\nEpoch: 600, Loss: 3.2435, Train: 1.0639, Val: 1.1074, Test: 1.0831\nEpoch: 700, Loss: 3.1874, Train: 1.0746, Val: 1.1120, Test: 1.0897\nEpoch: 800, Loss: 3.1470, Train: 1.0530, Val: 1.0947, Test: 1.0715\nEpoch: 900, Loss: 2.9948, Train: 1.0280, Val: 1.0727, Test: 1.0560\nEpoch: 999, Loss: 2.9923, Train: 1.0214, Val: 1.0734, Test: 1.0552\n","output_type":"stream"}]},{"cell_type":"code","source":"model_gat = ModelGAT(hidden_channels=64, encoder_layers=0, heads=4).to(device)\noptimizer_gat = torch.optim.Adam(model_gat.parameters(), lr=0.01)\n\nstart_train(model_gat, optimizer_gat, max_epochs=1000, print_each=100)","metadata":{"execution":{"iopub.status.busy":"2023-12-16T18:17:21.910950Z","iopub.execute_input":"2023-12-16T18:17:21.911592Z","iopub.status.idle":"2023-12-16T18:18:08.780742Z","shell.execute_reply.started":"2023-12-16T18:17:21.911557Z","shell.execute_reply":"2023-12-16T18:18:08.779804Z"},"trusted":true},"execution_count":464,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/999 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1330edeaab6f43818a6521e45eddc1d0"}},"metadata":{}},{"name":"stdout","text":"Epoch: 100, Loss: 4.0158, Train: 1.1042, Val: 1.1127, Test: 1.0937\nEpoch: 200, Loss: 3.4911, Train: 1.0982, Val: 1.1213, Test: 1.0963\nEpoch: 300, Loss: 3.1613, Train: 1.0865, Val: 1.1203, Test: 1.0979\nEpoch: 400, Loss: 3.0196, Train: 1.0779, Val: 1.1189, Test: 1.0999\nEpoch: 500, Loss: 2.9405, Train: 1.1282, Val: 1.1683, Test: 1.1566\nEpoch: 600, Loss: 2.8763, Train: 1.0859, Val: 1.1397, Test: 1.1270\nEpoch: 700, Loss: 2.7768, Train: 1.0863, Val: 1.1377, Test: 1.1314\nEpoch: 800, Loss: 2.7122, Train: 1.0728, Val: 1.1313, Test: 1.1298\nEpoch: 900, Loss: 2.7019, Train: 1.0642, Val: 1.1273, Test: 1.1277\nEpoch: 999, Loss: 2.6808, Train: 1.0570, Val: 1.1252, Test: 1.1192\n","output_type":"stream"}]},{"cell_type":"code","source":"model_gat = ModelGAT(hidden_channels=64, encoder_layers=0, heads=8).to(device)\noptimizer_gat = torch.optim.Adam(model_gat.parameters(), lr=0.001)\n\nstart_train(model_gat, optimizer_gat, max_epochs=1000, print_each=100)","metadata":{"execution":{"iopub.status.busy":"2023-12-16T18:07:50.329919Z","iopub.execute_input":"2023-12-16T18:07:50.330319Z","iopub.status.idle":"2023-12-16T18:09:04.128324Z","shell.execute_reply.started":"2023-12-16T18:07:50.330291Z","shell.execute_reply":"2023-12-16T18:09:04.127353Z"},"trusted":true},"execution_count":457,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/999 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e0295a51dd9240c780297d8e3ba9a0be"}},"metadata":{}},{"name":"stdout","text":"Epoch: 100, Loss: 5.3128, Train: 1.2289, Val: 1.2453, Test: 1.2321\nEpoch: 200, Loss: 4.4575, Train: 1.1690, Val: 1.1807, Test: 1.1613\nEpoch: 300, Loss: 4.1129, Train: 1.1360, Val: 1.1603, Test: 1.1279\nEpoch: 400, Loss: 3.6627, Train: 1.1218, Val: 1.1474, Test: 1.1113\nEpoch: 500, Loss: 3.4442, Train: 1.1607, Val: 1.1946, Test: 1.1556\nEpoch: 600, Loss: 3.2731, Train: 1.0904, Val: 1.1302, Test: 1.0954\nEpoch: 700, Loss: 3.1963, Train: 1.1024, Val: 1.1361, Test: 1.0992\nEpoch: 800, Loss: 3.1096, Train: 1.1247, Val: 1.1595, Test: 1.1210\nEpoch: 900, Loss: 3.0998, Train: 1.1170, Val: 1.1531, Test: 1.1170\nEpoch: 999, Loss: 2.9952, Train: 1.1049, Val: 1.1459, Test: 1.1109\n","output_type":"stream"}]},{"cell_type":"code","source":"model_gat = ModelGAT(hidden_channels=64, encoder_layers=1, heads=2).to(device)\noptimizer_gat = torch.optim.Adam(model_gat.parameters(), lr=0.005)\n\nstart_train(model_gat, optimizer_gat, max_epochs=1000, print_each=100)","metadata":{"execution":{"iopub.status.busy":"2023-12-16T18:23:54.246551Z","iopub.execute_input":"2023-12-16T18:23:54.246955Z","iopub.status.idle":"2023-12-16T18:24:42.980856Z","shell.execute_reply.started":"2023-12-16T18:23:54.246924Z","shell.execute_reply":"2023-12-16T18:24:42.979941Z"},"trusted":true},"execution_count":468,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/999 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ed61ea238de34de6a921c1cadecd1f6d"}},"metadata":{}},{"name":"stdout","text":"Epoch: 100, Loss: 5.1738, Train: 1.0620, Val: 1.0964, Test: 1.0849\nEpoch: 200, Loss: 4.5964, Train: 1.0622, Val: 1.1061, Test: 1.0906\nEpoch: 300, Loss: 4.4405, Train: 1.0371, Val: 1.0877, Test: 1.0657\nEpoch: 400, Loss: 3.9395, Train: 1.4496, Val: 1.4728, Test: 1.4703\nEpoch: 500, Loss: 3.8427, Train: 1.5670, Val: 1.5816, Test: 1.5883\nEpoch: 600, Loss: 3.6192, Train: 1.2957, Val: 1.3194, Test: 1.3199\nEpoch: 700, Loss: 3.5235, Train: 1.2418, Val: 1.2628, Test: 1.2617\nEpoch: 800, Loss: 3.4134, Train: 1.5704, Val: 1.5805, Test: 1.5860\nEpoch: 900, Loss: 3.3780, Train: 1.7339, Val: 1.7393, Test: 1.7533\nEpoch: 999, Loss: 3.4880, Train: 1.5358, Val: 1.5429, Test: 1.5506\n","output_type":"stream"}]},{"cell_type":"code","source":"model_gat = ModelGAT(hidden_channels=80, encoder_layers=0, heads=4).to(device)\noptimizer_gat = torch.optim.Adam(model_gat.parameters(), lr=0.001)\n\nstart_train(model_gat, optimizer_gat, max_epochs=1000, print_each=100)","metadata":{"execution":{"iopub.status.busy":"2023-12-16T18:09:51.754603Z","iopub.execute_input":"2023-12-16T18:09:51.754922Z","iopub.status.idle":"2023-12-16T18:10:49.351718Z","shell.execute_reply.started":"2023-12-16T18:09:51.754889Z","shell.execute_reply":"2023-12-16T18:10:49.350746Z"},"trusted":true},"execution_count":459,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/999 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"43bd4a9e885f4c49be65b80953abd06e"}},"metadata":{}},{"name":"stdout","text":"Epoch: 100, Loss: 5.1797, Train: 1.2058, Val: 1.2197, Test: 1.2065\nEpoch: 200, Loss: 4.5211, Train: 1.1683, Val: 1.1785, Test: 1.1560\nEpoch: 300, Loss: 4.1476, Train: 1.1343, Val: 1.1593, Test: 1.1269\nEpoch: 400, Loss: 3.6012, Train: 1.0584, Val: 1.0858, Test: 1.0609\nEpoch: 500, Loss: 3.5085, Train: 1.0638, Val: 1.0947, Test: 1.0717\nEpoch: 600, Loss: 3.4349, Train: 1.0979, Val: 1.1348, Test: 1.1088\nEpoch: 700, Loss: 3.3463, Train: 1.0789, Val: 1.1141, Test: 1.0862\nEpoch: 800, Loss: 3.1835, Train: 1.0861, Val: 1.1254, Test: 1.0971\nEpoch: 900, Loss: 3.0586, Train: 1.0723, Val: 1.1168, Test: 1.0904\nEpoch: 999, Loss: 2.9751, Train: 1.0532, Val: 1.0997, Test: 1.0789\n","output_type":"stream"}]},{"cell_type":"code","source":"model_gat = ModelGAT(hidden_channels=80, encoder_layers=0, heads=4).to(device)\noptimizer_gat = torch.optim.Adam(model_gat.parameters(), lr=0.005)\n\nstart_train(model_gat, optimizer_gat, max_epochs=1000, print_each=100)","metadata":{"execution":{"iopub.status.busy":"2023-12-16T18:20:15.089089Z","iopub.execute_input":"2023-12-16T18:20:15.089437Z","iopub.status.idle":"2023-12-16T18:21:12.545108Z","shell.execute_reply.started":"2023-12-16T18:20:15.089412Z","shell.execute_reply":"2023-12-16T18:21:12.544175Z"},"trusted":true},"execution_count":466,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/999 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b0d7977158304beca4b322a3b68d5be7"}},"metadata":{}},{"name":"stdout","text":"Epoch: 100, Loss: 4.2414, Train: 1.1875, Val: 1.2021, Test: 1.1793\nEpoch: 200, Loss: 3.6659, Train: 1.1332, Val: 1.1674, Test: 1.1428\nEpoch: 300, Loss: 3.5407, Train: 1.0976, Val: 1.1274, Test: 1.1072\nEpoch: 400, Loss: 3.2267, Train: 1.0748, Val: 1.1115, Test: 1.0904\nEpoch: 500, Loss: 3.3046, Train: 1.1486, Val: 1.1831, Test: 1.1667\nEpoch: 600, Loss: 2.9951, Train: 1.0990, Val: 1.1380, Test: 1.1251\nEpoch: 700, Loss: 2.9112, Train: 1.0462, Val: 1.0950, Test: 1.0813\nEpoch: 800, Loss: 2.7637, Train: 1.0414, Val: 1.0971, Test: 1.0872\nEpoch: 900, Loss: 2.7222, Train: 1.0849, Val: 1.1428, Test: 1.1400\nEpoch: 999, Loss: 2.6722, Train: 1.0077, Val: 1.0807, Test: 1.0641\n","output_type":"stream"}]},{"cell_type":"code","source":"model_gat = ModelGAT(hidden_channels=128, encoder_layers=2, heads=5).to(device)\noptimizer_gat = torch.optim.Adam(model_gat.parameters(), lr=0.001)\n\nstart_train(model_gat, optimizer_gat, max_epochs=1000, print_each=100)","metadata":{"execution":{"iopub.status.busy":"2023-12-16T18:12:32.588970Z","iopub.execute_input":"2023-12-16T18:12:32.589334Z","iopub.status.idle":"2023-12-16T18:16:23.706176Z","shell.execute_reply.started":"2023-12-16T18:12:32.589303Z","shell.execute_reply":"2023-12-16T18:16:23.705188Z"},"trusted":true},"execution_count":462,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/999 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"73179128770749cd801f8c5dc588e565"}},"metadata":{}},{"name":"stdout","text":"Epoch: 100, Loss: 5.2538, Train: 1.0965, Val: 1.1131, Test: 1.0990\nEpoch: 200, Loss: 4.9420, Train: 1.1756, Val: 1.1894, Test: 1.1654\nEpoch: 300, Loss: 4.7979, Train: 1.1778, Val: 1.1999, Test: 1.1739\nEpoch: 400, Loss: 4.6481, Train: 1.1146, Val: 1.1405, Test: 1.1120\nEpoch: 500, Loss: 4.2150, Train: 1.0698, Val: 1.0939, Test: 1.0712\nEpoch: 600, Loss: 3.9422, Train: 1.0998, Val: 1.1254, Test: 1.1052\nEpoch: 700, Loss: 3.9681, Train: 1.1418, Val: 1.1636, Test: 1.1447\nEpoch: 800, Loss: 3.9500, Train: 1.1392, Val: 1.1722, Test: 1.1439\nEpoch: 900, Loss: 3.7133, Train: 1.1358, Val: 1.1642, Test: 1.1406\nEpoch: 999, Loss: 3.7397, Train: 1.2707, Val: 1.2884, Test: 1.2801\n","output_type":"stream"}]},{"cell_type":"code","source":"model_gat = ModelGAT(hidden_channels=128, encoder_layers=1, heads=4).to(device)\noptimizer_gat = torch.optim.Adam(model_gat.parameters(), lr=0.005)\n\nstart_train(model_gat, optimizer_gat, max_epochs=1000, print_each=100)","metadata":{"execution":{"iopub.status.busy":"2023-12-16T18:26:06.541933Z","iopub.execute_input":"2023-12-16T18:26:06.542698Z","iopub.status.idle":"2023-12-16T18:28:22.021281Z","shell.execute_reply.started":"2023-12-16T18:26:06.542666Z","shell.execute_reply":"2023-12-16T18:28:22.020170Z"},"trusted":true},"execution_count":470,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/999 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2b01c19a32314fab90cc582c5c510362"}},"metadata":{}},{"name":"stdout","text":"Epoch: 100, Loss: 5.2330, Train: 1.1799, Val: 1.2096, Test: 1.1972\nEpoch: 200, Loss: 4.6729, Train: 1.0219, Val: 1.0702, Test: 1.0438\nEpoch: 300, Loss: 4.2860, Train: 1.1576, Val: 1.1945, Test: 1.1463\nEpoch: 400, Loss: 3.8653, Train: 1.1413, Val: 1.1783, Test: 1.1550\nEpoch: 500, Loss: 3.7040, Train: 1.1263, Val: 1.1652, Test: 1.1364\nEpoch: 600, Loss: 3.4120, Train: 1.0808, Val: 1.1179, Test: 1.0999\nEpoch: 700, Loss: 3.3644, Train: 1.0965, Val: 1.1358, Test: 1.1095\nEpoch: 800, Loss: 3.2905, Train: 1.0799, Val: 1.1203, Test: 1.1007\nEpoch: 900, Loss: 3.2085, Train: 1.0728, Val: 1.1159, Test: 1.0971\nEpoch: 999, Loss: 3.1055, Train: 1.0298, Val: 1.0751, Test: 1.0580\n","output_type":"stream"}]},{"cell_type":"code","source":"model_gat = ModelGAT(hidden_channels=128, encoder_layers=1, heads=5).to(device)\noptimizer_gat = torch.optim.Adam(model_gat.parameters(), lr=0.005)\n\nstart_train(model_gat, optimizer_gat, max_epochs=1000, print_each=100)","metadata":{"execution":{"iopub.status.busy":"2023-12-16T18:32:13.472983Z","iopub.execute_input":"2023-12-16T18:32:13.473279Z","iopub.status.idle":"2023-12-16T18:34:56.776042Z","shell.execute_reply.started":"2023-12-16T18:32:13.473252Z","shell.execute_reply":"2023-12-16T18:34:56.775084Z"},"trusted":true},"execution_count":473,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/999 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9a67baf9fdd047e6956ac872f5d2d5e6"}},"metadata":{}},{"name":"stdout","text":"Epoch: 100, Loss: 5.2032, Train: 1.1524, Val: 1.1855, Test: 1.1651\nEpoch: 200, Loss: 4.2145, Train: 1.0431, Val: 1.0778, Test: 1.0537\nEpoch: 300, Loss: 4.9850, Train: 1.1767, Val: 1.2009, Test: 1.1812\nEpoch: 400, Loss: 3.6671, Train: 1.1427, Val: 1.1783, Test: 1.1564\nEpoch: 500, Loss: 3.5351, Train: 1.1141, Val: 1.1477, Test: 1.1269\nEpoch: 600, Loss: 3.4521, Train: 1.0851, Val: 1.1207, Test: 1.1051\nEpoch: 700, Loss: 3.4621, Train: 1.1068, Val: 1.1427, Test: 1.1259\nEpoch: 800, Loss: 3.3379, Train: 1.1021, Val: 1.1333, Test: 1.1193\nEpoch: 900, Loss: 3.2689, Train: 1.0679, Val: 1.1107, Test: 1.0939\nEpoch: 999, Loss: 3.0926, Train: 1.0652, Val: 1.1079, Test: 1.0913\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### Эта модель показала в один момент даже score 1.02, при этом не столкнулась с переобучением","metadata":{}},{"cell_type":"code","source":"model_gat = ModelGAT(hidden_channels=128, encoder_layers=1, heads=3).to(device)\noptimizer_gat = torch.optim.Adam(model_gat.parameters(), lr=0.005)\n\nstart_train(model_gat, optimizer_gat, max_epochs=1000, print_each=100)","metadata":{"execution":{"iopub.status.busy":"2023-12-16T18:35:02.295917Z","iopub.execute_input":"2023-12-16T18:35:02.296607Z","iopub.status.idle":"2023-12-16T18:36:52.746754Z","shell.execute_reply.started":"2023-12-16T18:35:02.296577Z","shell.execute_reply":"2023-12-16T18:36:52.745779Z"},"trusted":true},"execution_count":474,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/999 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2316029ae8dc4485a1cf281676b14549"}},"metadata":{}},{"name":"stdout","text":"Epoch: 100, Loss: 4.8322, Train: 1.0243, Val: 1.0683, Test: 1.0491\nEpoch: 200, Loss: 4.4309, Train: 1.0236, Val: 1.0671, Test: 1.0441\nEpoch: 300, Loss: 4.3275, Train: 1.0031, Val: 1.0479, Test: 1.0268\nEpoch: 400, Loss: 4.1384, Train: 1.0978, Val: 1.1441, Test: 1.1160\nEpoch: 500, Loss: 3.9613, Train: 1.2139, Val: 1.2576, Test: 1.2209\nEpoch: 600, Loss: 3.6545, Train: 1.1620, Val: 1.2053, Test: 1.1814\nEpoch: 700, Loss: 3.5236, Train: 1.1689, Val: 1.2067, Test: 1.1902\nEpoch: 800, Loss: 3.4349, Train: 1.0692, Val: 1.1185, Test: 1.0978\nEpoch: 900, Loss: 3.3673, Train: 1.1506, Val: 1.1912, Test: 1.1751\nEpoch: 999, Loss: 3.4448, Train: 1.0461, Val: 1.0931, Test: 1.0735\n","output_type":"stream"}]},{"cell_type":"code","source":"model_gat = ModelGAT(hidden_channels=128, encoder_layers=2, heads=3).to(device)\noptimizer_gat = torch.optim.Adam(model_gat.parameters(), lr=0.005)\n\nstart_train(model_gat, optimizer_gat, max_epochs=1000, print_each=100)","metadata":{"execution":{"iopub.status.busy":"2023-12-16T18:36:52.748477Z","iopub.execute_input":"2023-12-16T18:36:52.748772Z","iopub.status.idle":"2023-12-16T18:39:22.380759Z","shell.execute_reply.started":"2023-12-16T18:36:52.748746Z","shell.execute_reply":"2023-12-16T18:39:22.379739Z"},"trusted":true},"execution_count":475,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/999 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9d2ce9dbb1fb41fcada54adb2277c5c9"}},"metadata":{}},{"name":"stdout","text":"Epoch: 100, Loss: 5.9921, Train: 1.6832, Val: 1.7039, Test: 1.6840\nEpoch: 200, Loss: 4.9108, Train: 1.1342, Val: 1.1530, Test: 1.1295\nEpoch: 300, Loss: 4.6210, Train: 1.0639, Val: 1.0857, Test: 1.0700\nEpoch: 400, Loss: 4.2120, Train: 1.0370, Val: 1.0757, Test: 1.0646\nEpoch: 500, Loss: 4.0769, Train: 1.0960, Val: 1.1197, Test: 1.1041\nEpoch: 600, Loss: 3.8828, Train: 1.0905, Val: 1.1225, Test: 1.1139\nEpoch: 700, Loss: 3.6750, Train: 1.1779, Val: 1.1985, Test: 1.1760\nEpoch: 800, Loss: 3.7792, Train: 1.1612, Val: 1.1899, Test: 1.1729\nEpoch: 900, Loss: 3.4844, Train: 1.2323, Val: 1.2566, Test: 1.2468\nEpoch: 999, Loss: 3.4151, Train: 1.1113, Val: 1.1483, Test: 1.1359\n","output_type":"stream"}]},{"cell_type":"code","source":"model_gat = ModelGAT(hidden_channels=128, encoder_layers=2, heads=6).to(device)\noptimizer_gat = torch.optim.Adam(model_gat.parameters(), lr=0.005)\n\nstart_train(model_gat, optimizer_gat, max_epochs=1000, print_each=100)","metadata":{"execution":{"iopub.status.busy":"2023-12-16T18:39:22.382739Z","iopub.execute_input":"2023-12-16T18:39:22.383384Z","iopub.status.idle":"2023-12-16T18:43:59.124938Z","shell.execute_reply.started":"2023-12-16T18:39:22.383345Z","shell.execute_reply":"2023-12-16T18:43:59.123975Z"},"trusted":true},"execution_count":476,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/999 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"81a57e304d04420fa31d5459cc4e5cea"}},"metadata":{}},{"name":"stdout","text":"Epoch: 100, Loss: 4.9518, Train: 1.1687, Val: 1.1937, Test: 1.1661\nEpoch: 200, Loss: 9.9366, Train: 1.1914, Val: 1.2035, Test: 1.1755\nEpoch: 300, Loss: 4.5712, Train: 1.1288, Val: 1.1347, Test: 1.1111\nEpoch: 400, Loss: 4.1736, Train: 1.1713, Val: 1.1895, Test: 1.1731\nEpoch: 500, Loss: 4.2004, Train: 1.7632, Val: 1.7836, Test: 1.7971\nEpoch: 600, Loss: 3.9216, Train: 1.1625, Val: 1.1857, Test: 1.1640\nEpoch: 700, Loss: 3.7148, Train: 1.1684, Val: 1.1892, Test: 1.1668\nEpoch: 800, Loss: 3.5247, Train: 1.1866, Val: 1.2053, Test: 1.1796\nEpoch: 900, Loss: 3.3742, Train: 1.1539, Val: 1.1692, Test: 1.1375\nEpoch: 999, Loss: 3.3372, Train: 1.1851, Val: 1.2044, Test: 1.1756\n","output_type":"stream"}]},{"cell_type":"code","source":"model_gat = ModelGAT(hidden_channels=8 * 20, encoder_layers=1, heads=3).to(device)\noptimizer_gat = torch.optim.Adam(model_gat.parameters(), lr=0.005)\n\nstart_train(model_gat, optimizer_gat, max_epochs=1000, print_each=100)","metadata":{"execution":{"iopub.status.busy":"2023-12-16T18:43:59.126750Z","iopub.execute_input":"2023-12-16T18:43:59.127084Z","iopub.status.idle":"2023-12-16T18:46:17.028872Z","shell.execute_reply.started":"2023-12-16T18:43:59.127055Z","shell.execute_reply":"2023-12-16T18:46:17.027890Z"},"trusted":true},"execution_count":477,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/999 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b381f61f1fe743c482acc938fcc9723f"}},"metadata":{}},{"name":"stdout","text":"Epoch: 100, Loss: 4.9088, Train: 1.1036, Val: 1.1391, Test: 1.1224\nEpoch: 200, Loss: 4.5454, Train: 1.0614, Val: 1.1051, Test: 1.0811\nEpoch: 300, Loss: 4.2345, Train: 1.0278, Val: 1.0730, Test: 1.0520\nEpoch: 400, Loss: 3.7955, Train: 1.0934, Val: 1.1327, Test: 1.1111\nEpoch: 500, Loss: 3.5925, Train: 1.1173, Val: 1.1589, Test: 1.1469\nEpoch: 600, Loss: 3.5038, Train: 1.0987, Val: 1.1349, Test: 1.1224\nEpoch: 700, Loss: 3.4772, Train: 1.1234, Val: 1.1564, Test: 1.1455\nEpoch: 800, Loss: 3.3589, Train: 1.1573, Val: 1.1902, Test: 1.1804\nEpoch: 900, Loss: 3.2840, Train: 1.0729, Val: 1.1086, Test: 1.0982\nEpoch: 999, Loss: 3.2843, Train: 1.1630, Val: 1.1900, Test: 1.1943\n","output_type":"stream"}]},{"cell_type":"code","source":"model_gat = ModelGAT(hidden_channels=128, encoder_layers=1, heads=3).to(device)\noptimizer_gat = torch.optim.Adam(model_gat.parameters(), lr=0.005)\n\nstart_train(model_gat, optimizer_gat, max_epochs=5000, print_each=100)","metadata":{"execution":{"iopub.status.busy":"2023-12-16T18:46:41.362692Z","iopub.execute_input":"2023-12-16T18:46:41.363496Z","iopub.status.idle":"2023-12-16T18:55:51.826466Z","shell.execute_reply.started":"2023-12-16T18:46:41.363465Z","shell.execute_reply":"2023-12-16T18:55:51.825470Z"},"trusted":true},"execution_count":478,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/4999 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b69c195d4ebe4856a55cf13246c13c25"}},"metadata":{}},{"name":"stdout","text":"Epoch: 100, Loss: 4.9427, Train: 1.2372, Val: 1.2702, Test: 1.2494\nEpoch: 200, Loss: 4.4675, Train: 1.2055, Val: 1.2343, Test: 1.2059\nEpoch: 300, Loss: 3.6148, Train: 1.1348, Val: 1.1693, Test: 1.1547\nEpoch: 400, Loss: 3.5126, Train: 1.1012, Val: 1.1375, Test: 1.1199\nEpoch: 500, Loss: 3.3875, Train: 1.1335, Val: 1.1681, Test: 1.1488\nEpoch: 600, Loss: 3.3160, Train: 1.0979, Val: 1.1431, Test: 1.1194\nEpoch: 700, Loss: 3.3056, Train: 1.0973, Val: 1.1391, Test: 1.1193\nEpoch: 800, Loss: 3.1608, Train: 1.1126, Val: 1.1568, Test: 1.1340\nEpoch: 900, Loss: 3.1805, Train: 1.0718, Val: 1.1165, Test: 1.1043\nEpoch: 1000, Loss: 3.1041, Train: 1.0858, Val: 1.1317, Test: 1.1203\nEpoch: 1100, Loss: 3.0961, Train: 1.0275, Val: 1.0761, Test: 1.0624\nEpoch: 1200, Loss: 2.9863, Train: 1.0497, Val: 1.1018, Test: 1.0852\nEpoch: 1300, Loss: 2.9583, Train: 1.0692, Val: 1.1266, Test: 1.1101\nEpoch: 1400, Loss: 2.9421, Train: 1.0573, Val: 1.1082, Test: 1.0934\nEpoch: 1500, Loss: 2.8465, Train: 1.0506, Val: 1.0990, Test: 1.1020\nEpoch: 1600, Loss: 2.7743, Train: 1.0040, Val: 1.0640, Test: 1.0550\nEpoch: 1700, Loss: 2.7754, Train: 1.0499, Val: 1.1111, Test: 1.1034\nEpoch: 1800, Loss: 3.1134, Train: 1.0034, Val: 1.0751, Test: 1.0640\nEpoch: 1900, Loss: 2.7319, Train: 1.0304, Val: 1.1020, Test: 1.0872\nEpoch: 2000, Loss: 2.6255, Train: 1.0366, Val: 1.1108, Test: 1.0897\nEpoch: 2100, Loss: 2.6847, Train: 1.0184, Val: 1.0965, Test: 1.0857\nEpoch: 2200, Loss: 2.5511, Train: 1.0012, Val: 1.0804, Test: 1.0686\nEpoch: 2300, Loss: 2.6535, Train: 1.0024, Val: 1.0755, Test: 1.0675\nEpoch: 2400, Loss: 2.5339, Train: 1.0238, Val: 1.1086, Test: 1.0839\nEpoch: 2500, Loss: 2.5123, Train: 0.9858, Val: 1.0758, Test: 1.0577\nEpoch: 2600, Loss: 2.3865, Train: 0.9860, Val: 1.0767, Test: 1.0601\nEpoch: 2700, Loss: 2.4764, Train: 0.9742, Val: 1.0779, Test: 1.0576\nEpoch: 2800, Loss: 2.4695, Train: 0.9962, Val: 1.0968, Test: 1.0755\nEpoch: 2900, Loss: 2.3790, Train: 1.0039, Val: 1.0977, Test: 1.0877\nEpoch: 3000, Loss: 2.4094, Train: 0.9780, Val: 1.0814, Test: 1.0655\nEpoch: 3100, Loss: 2.3071, Train: 0.9419, Val: 1.0531, Test: 1.0196\nEpoch: 3200, Loss: 2.3042, Train: 0.9942, Val: 1.0935, Test: 1.0816\nEpoch: 3300, Loss: 2.2245, Train: 1.0217, Val: 1.1337, Test: 1.1153\nEpoch: 3400, Loss: 2.3471, Train: 0.9262, Val: 1.0326, Test: 1.0233\nEpoch: 3500, Loss: 2.2483, Train: 0.9481, Val: 1.0667, Test: 1.0555\nEpoch: 3600, Loss: 2.2309, Train: 0.9396, Val: 1.0495, Test: 1.0334\nEpoch: 3700, Loss: 2.1744, Train: 0.9272, Val: 1.0419, Test: 1.0308\nEpoch: 3800, Loss: 2.1758, Train: 0.9300, Val: 1.0505, Test: 1.0362\nEpoch: 3900, Loss: 2.1428, Train: 0.9695, Val: 1.0917, Test: 1.0712\nEpoch: 4000, Loss: 2.1591, Train: 0.9391, Val: 1.0769, Test: 1.0514\nEpoch: 4100, Loss: 2.1347, Train: 0.9783, Val: 1.1016, Test: 1.0847\nEpoch: 4200, Loss: 2.0533, Train: 0.9417, Val: 1.0723, Test: 1.0546\nEpoch: 4300, Loss: 2.0308, Train: 0.9323, Val: 1.0616, Test: 1.0485\nEpoch: 4400, Loss: 2.0302, Train: 0.9116, Val: 1.0486, Test: 1.0331\nEpoch: 4500, Loss: 2.0821, Train: 0.9270, Val: 1.0569, Test: 1.0343\nEpoch: 4600, Loss: 1.9961, Train: 0.9251, Val: 1.0542, Test: 1.0299\nEpoch: 4700, Loss: 1.9790, Train: 0.9117, Val: 1.0452, Test: 1.0329\nEpoch: 4800, Loss: 1.9782, Train: 0.9264, Val: 1.0499, Test: 1.0397\nEpoch: 4900, Loss: 1.9989, Train: 0.9228, Val: 1.0601, Test: 1.0342\nEpoch: 4999, Loss: 1.9224, Train: 0.9047, Val: 1.0403, Test: 1.0195\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Получил стабильно обучающуюся модель на GATConv, rmse 1.0195, и она продолжает спокойно обучаться","metadata":{}}]}